<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://luminqiang.github.io/</id>
    <title>卢敏强的博客</title>
    <updated>2019-12-26T14:17:23.439Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://luminqiang.github.io/"/>
    <link rel="self" href="https://luminqiang.github.io//atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://luminqiang.github.io//images/avatar.png</logo>
    <icon>https://luminqiang.github.io//favicon.ico</icon>
    <rights>All rights reserved 2019, 卢敏强的博客</rights>
    <entry>
        <title type="html"><![CDATA[HTTP学习笔记之连接管理]]></title>
        <id>https://luminqiang.github.io//post/http-xue-xi-bi-ji-zhi-lian-jie-guan-li</id>
        <link href="https://luminqiang.github.io//post/http-xue-xi-bi-ji-zhi-lian-jie-guan-li">
        </link>
        <updated>2019-12-26T13:41:58.000Z</updated>
        <content type="html"><![CDATA[<p>HTTP的性能中规中矩，不算差，并不够好，比不上RPC这种协议，但是胜在简单方便，关于http的连接，则分为短连接与长连接。</p>
<p>短连接<br>
HTTP 协议的最初版本0.9/1.0，是个非常简单的协议，通信过程也采用了简单的“请求 - 应答”方式。</p>
<p>它底层的数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接。</p>
<p>因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为“<strong>短连接</strong>”（short-lived connections）。早期的 HTTP 协议也被称为是“<strong>无连接</strong>”的协议。</p>
<p><strong>短连接的缺点：</strong><br>
在 TCP 协议里，建立连接和关闭连接都是非常“昂贵”的操作。<br>
TCP 建立连接要有“三次握手”，发送 3 个数据包，需要 1 个 RTT；<br>
关闭连接是“四次挥手”，4 个数据包需要 2 个 RTT。</p>
<p><strong>什么是RTT？</strong><br>
RTT=传播时延（往返）+排队时延（路由器和交换机的）+数据处理时延（应用程序的）<br>
<img src="https://pic2.zhimg.com/v2-99e600bf39d58d7732b159325ca0caf7_r.jpg" alt=""></p>
<p>而即使 HTTP最简单的一次“请求 - 响应”通常需要 4 个包，如果不算服务器内部的处理时间，最多是 2 个 RTT。这么算下来，浪费的时间就是“3÷5=60%”，有三分之二的时间被浪费掉了，传输效率低得惊人。<br>
<img src="https://static001.geekbang.org/resource/image/54/0c/54315ed9ac37fbc6547258040f00a80c.png" alt=""></p>
<p><strong>长连接</strong><br>
针对短连接暴露出的缺点，HTTP 协议就提出了“长连接”的通信方式，也叫“持久连接”（persistent connections）、“连接保活”（keep alive）、“连接复用”（connection reuse）。</p>
<p>其解决思路为“成本均摊”，既然 TCP 的连接和关闭非常耗时间，那么就把这个时间成本由原来的一个“请求 - 应答”均摊到多个“请求 - 应答”上。</p>
<p>虽然不能改善 TCP 的连接效率，但基于“分母效应”，每个“请求 - 应答”的无效时间就会降低不少，整体传输效率也就提高了。</p>
<p><strong>短连接与长连接的对比示意图</strong><br>
<img src="https://static001.geekbang.org/resource/image/57/b4/57b3d80234a1f1b8c538a376aa01d3b4.png" alt=""></p>
<p>在短连接里发送了三次 HTTP“请求 - 应答”，每次都会浪费 60% 的 RTT 时间。而在长连接的情况下，同样发送三次请求，因为只在第一次时建立连接，在最后一次时关闭连接，所以浪费率就是“3÷9≈33%”，降低了差不多一半的时间损耗。显然，如果在这个长连接上发送的请求越多，分母就越大，利用率也就越高。</p>
<p><strong>连接相关的头字段</strong><br>
由于长连接对性能的改善效果非常显著，所以在 HTTP/1.1 中的连接都会默认启用长连接。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的 TCP 连接，也就是长连接，在这个连接上收发数据。</p>
<p>当然，我们也可以在请求头里明确地要求使用长连接机制，使用的字段是<strong>Connection</strong>，值是“<strong>keep-alive</strong>”。</p>
<p>如果服务器支持长连接，它总会在响应报文里放一个“<strong>Connection: keep-alive</strong>”字段，告诉客户端：“我是支持长连接的，接下来就用这个 TCP 一直收发数据吧”。</p>
<p><strong>长连接的缺点</strong></p>
<p>因为 TCP 连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗尽服务器的资源，导致服务器无法为真正有需要的用户提供服务。</p>
<p>所以，长连接也需要在恰当的时间关闭，不能永远保持与服务器的连接，这在客户端或者服务器都可以做到：</p>
<p>在客户端，可以在请求头里加上“Connection: close”字段，告诉服务器：“这次通信后就关闭连接”。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也加上这个字段，发送之后就调用 Socket API 关闭 TCP 连接。</p>
<p>服务器端通常不会主动关闭连接，但也可以使用一些策略。拿 Nginx 来举例，它有两种方式：</p>
<p>1.使用“keepalive_timeout”指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。</p>
<p>2.使用“keepalive_requests”指令，设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接。</p>
<p><strong>队头阻塞：</strong></p>
<p>什么是队头阻塞？<br>
因为 HTTP 规定报文必须是“一发一收”，这就形成了一个先进先出的“串行”队列。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理。如果队首的请求耽误时间，队列里后的所有请求阻塞起等待。<br>
<img src="https://static001.geekbang.org/resource/image/6a/72/6a6d30a89fb085d5f1773a887aaf5572.png" alt=""></p>
<p><strong>优化队头阻塞问题</strong><br>
“请求 - 应答”模型不能变，所以“队头阻塞”问题在 HTTP/1.1 里无法解决，只能缓解：</p>
<p>1.采用就是“<strong>并发连接</strong>”（concurrent connections），也就是同时对一个域名发起多个长连接，用数量来解决质量的问题。</p>
<p>缺陷：如果客户端随意建立多个连接，用户数 x 并发数，将会形成巨大的连接数，服务器资源很快耗尽，最后拒绝响应。浏览器一般并发连接数为6-8。</p>
<p>2.采用“<strong>域名分片</strong>”（domain sharding）技术，还是用数量来解决质量的思路。<br>
多个域名都指向同一台服务器 www.chrono.com，这样实际长连接的数量就又上去了。</p>
<figure data-type="image" tabindex="1"><img src="https://static001.geekbang.org/resource/image/f9/72/f93afe4b663d681b8ce63c947f478072.png" alt=""></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HTTP的实体数据]]></title>
        <id>https://luminqiang.github.io//post/http-de-shi-ti-shu-ju</id>
        <link href="https://luminqiang.github.io//post/http-de-shi-ti-shu-ju">
        </link>
        <updated>2019-12-25T15:02:52.000Z</updated>
        <content type="html"><![CDATA[<p><strong>数据类型与编码</strong><br>
在 TCP/IP 协议栈里，传输数据基本上都是“header+body”的格式。但 TCP、UDP 因为是传输层的协议，它们不会关心 body 数据是什么，只要把数据发送到对方就算是完成了任务。</p>
<p>而 HTTP 协议则不同，它是应用层的协议，数据到达之后工作只能说是完成了一半，还必须要告诉上层应用这是什么数据才行，否则上层应用就会“不知所措”。</p>
<p>你可以设想一下，假如 HTTP 没有告知数据类型的功能，服务器把“一大坨”数据发给了浏览器，浏览器看到的是一个“黑盒子”，这时候该怎么办呢？</p>
<p>当然，它可以“猜”。因为很多数据都是有固定格式的，所以通过检查数据的前几个字节也许就能知道这是个 GIF 图片、或者是个 MP3 音乐文件，但这种方式无疑十分低效，而且有很大几率会检查不出来文件类型。</p>
<p>幸运的是，早在 HTTP 协议诞生之前就已经有了针对这种问题的解决方案，不过它是用在电子邮件系统里的，让电子邮件可以发送 ASCII 码以外的任意数据，方案的名字叫做“多用途互联网邮件扩展”（Multipurpose Internet Mail Extensions），简称为 MIME。</p>
<p>MIME 是一个很大的标准规范，但 HTTP 只“顺手牵羊”取了其中的一部分，用来标记 body 的数据类型，这就是我们平常总能听到的“MIME type”。</p>
<p>MIME 把数据分成了八大类，每个大类下再细分出多个子类，形式是“type/subtype”的字符串，巧得很，刚好也符合了 HTTP 明文的特点，所以能够很容易地纳入 HTTP 头字段里。</p>
<p>这里简单列举一下在 HTTP 里经常遇到的几个类别：</p>
<p>text：即文本格式的可读数据，我们最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本 text/plain、样式表 text/css 等。<br>
image：即图像文件，有 image/gif、image/jpeg、image/png 等。<br>
audio/video：音频和视频数据，例如 audio/mpeg、video/mp4 等。<br>
application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有 application/json，application/javascript、application/pdf 等，另外，如果实在是不知道数据是什么类型，像刚才说的“黑盒”，就会是 application/octet-stream，即不透明的二进制数据。<br>
但仅有 MIME type 还不够，因为 HTTP 在传输时为了节约带宽，有时候还会压缩数据，为了不要让浏览器继续“猜”，还需要有一个“Encoding type”，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。</p>
<p>比起 MIME type 来说，Encoding type 就少了很多，常用的只有下面三种：</p>
<p>gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式；<br>
deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip；<br>
br：一种专门为 HTTP 优化的新压缩算法（Brotli）。</p>
]]></content>
    </entry>
</feed>